# 七月在线-一站式刷遍各大互联网公司人工智能笔试面试题

## 面试大题-机器学习
### 2、哪些机器学习算法不需要做归一化处理？
解析：

在实际应用中，通过梯度下降法求解的模型一般都是需要归一化的，比如线性回归、logistic回归、KNN、SVM、神经网络等模型。

但树形模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、随机森林(Random Forest)。

其他如管博士所说，我归一化和标准化主要是为了使计算更方便 比如两个变量的量纲不同 可能一个的数值远大于另一个那么他们同时作为变量的时候 可能会造成数值计算的问题，比如说求矩阵的逆可能很不精确 或者梯度下降法的收敛比较困难，还有如果需要计算欧式距离的话可能 量纲也需要调整 所以我估计lr 和 knn 标准化一下应该有好处。
至于其他的算法 我也觉得如果变量量纲差距很大的话 先标准化一下会有好处。

我们会经常提到标准化、归一化，那到底什么是标准化和归一化呢？

标准化：特征均值为0，方差为1
公式：
![](https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase64155058398881840727.png)

归一化：把每个特征向量（特别是奇异样本数据）的值都缩放到相同数值范围，如[0,1]或[-1,1]。

最常用的归一化形式就是将特征向量调整为L1范数（就是绝对值相加），使特征向量的数值之和为1。
而L2范数就是欧几里得之和。
data_normalized = preprocessing.normalize( data , norm="L1" )

公式：
![](https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase64155058399446105850.png)

这个方法经常用于确保数据点没有因为特征的基本性质而产生较大差异，即确保数据处于同一数量级（同一量纲），提高不同特征数据的可比性。

关于什么是归一化，更多请参见：https://www.julyedu.com/question/big/kp_id/23/ques_id/1011

### 3、树形结构为什么不需要归一化？
解析：

因为数值缩放不影响分裂点位置，对树模型的结构不造成影响。
按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。而且，树模型是不能进行梯度下降的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此树模型是阶跃的，阶跃点是不可导的，并且求导没意义，也就不需要归一化。

既然树形结构（如决策树、RF）不需要归一化，那为何非树形结构比如Adaboost、SVM、LR、Knn、KMeans之类则需要归一化呢？

对于线性模型，特征值差别很大时，比如说LR，我有两个特征，一个是(0,1)的，一个是(0,10000)的，运用梯度下降的时候，损失等高线是椭圆形，需要进行多次迭代才能到达最优点。
但是如果进行了归一化，那么等高线就是圆形的，促使SGD往原点迭代，从而导致需要的迭代次数较少。

除了归一化，我们还会经常提到标准化，那到底什么是标准化和归一化呢？

标准化：特征均值为0，方差为1
公式：
![](https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase64155058398881840727.png)


归一化：把每个特征向量（特别是奇异样本数据）的值都缩放到相同数值范围，如[0,1]或[-1,1]。

最常用的归一化形式就是将特征向量调整为L1范数（就是绝对值相加），使特征向量的数值之和为1。
而L2范数就是欧几里得之和。
data_normalized = preprocessing.normalize( data , norm="L1" )

公式：
![](https://julyedu-img.oss-cn-beijing.aliyuncs.com/quesbase64155058399446105850.png)

这个方法经常用于确保数据点没有因为特征的基本性质而产生较大差异，即确保数据处于同一数量级（同一量纲），提高不同特征数据的可比性。
